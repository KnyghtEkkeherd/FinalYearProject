{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bytetracker import BYTETracker\n",
    "from bytetracker.basetrack import BaseTrack\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 129 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\", task=\"detect\")\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = BYTETracker()\n",
    "BaseTrack._count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_all_bbox_on_image(image, tracking_objects: np.ndarray):\n",
    "    \"\"\"\n",
    "    A list of of detections with track id, class id and confidence.\n",
    "            [\n",
    "                [x, y, x, y, track_id, class_id, conf],\n",
    "                [x, y, x, y, track_id, class_id, conf],\n",
    "                ...\n",
    "            ]\n",
    "\n",
    "    Plot this on the image with the track id, class id and confidence.\n",
    "    \"\"\"\n",
    "    for detection in tracking_objects:\n",
    "        x1, y1, x2, y2, track_id, _, conf = detection\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            f\"{int(track_id)} ({conf:.2f})\",\n",
    "            (x1, y1 - 10),\n",
    "            0,\n",
    "            1,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "def yolo_results_to_bytetrack_format(detections):\n",
    "    \"\"\"Transforms YOLO detections into the bytetrack format.\n",
    "\n",
    "    Args:\n",
    "        detections: A list of YOLO detections.\n",
    "\n",
    "    Returns:\n",
    "        A list of bytetrack detections.\n",
    "    \"\"\"\n",
    "    boxes = detections.numpy().boxes.xyxyn\n",
    "    scores = detections.numpy().boxes.conf\n",
    "    classes = detections.numpy().boxes.cls\n",
    "    return np.stack(\n",
    "        [\n",
    "            boxes[:, 0],\n",
    "            boxes[:, 1],\n",
    "            boxes[:, 2],\n",
    "            boxes[:, 3],\n",
    "            scores,\n",
    "            classes,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def scale_bbox_as_xyxy(bbox: np.ndarray, target_img_size: tuple):\n",
    "    \"\"\"Scales a bounding box to a target image size.\n",
    "\n",
    "    Args:\n",
    "        bbox: A bounding box in the format [x, y, x, y].\n",
    "        target_img_size: The target image size as a tuple (h, W).\n",
    "\n",
    "    Returns:\n",
    "        The scaled bounding box.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    h, w = target_img_size\n",
    "    scaled_bbox = np.array([x1 * w, y1 * h, x2 * w, y2 * h])\n",
    "    return scaled_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        time.sleep(0.01)\n",
    "        continue\n",
    "\n",
    "    frame_id += 1\n",
    "    frame_tracked = []\n",
    "\n",
    "    detections = model.predict(frame, classes=0, conf=0.25, verbose=False)[0]\n",
    "    for detection in detections:\n",
    "        boxes = detections.numpy().boxes.xyxyn\n",
    "        scores = detections.numpy().boxes.conf\n",
    "        classes = detections.numpy().boxes.cls\n",
    "\n",
    "        formatted = np.stack([boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3], scores, classes,], axis=1)\n",
    "        tracked = tracker.update(formatted, frame_id)\n",
    "\n",
    "        if len(tracked) > 0:\n",
    "            tracked_objects = np.insert(tracked, 0, frame_id, axis=1)\n",
    "            # print(f\"Tracked objects with frame_id: {tracked_objects}\")\n",
    "            frame_tracked.append(tracked_objects)\n",
    "\n",
    "    if frame_tracked:\n",
    "        df_tracked = pd.DataFrame(np.concatenate(frame_tracked), columns=[\"frame_id\", \"x1\", \"y1\", \"x2\", \"y2\", \"track_id\", \"class\", \"confidence\"])\n",
    "        df_tracked[[\"x1\", \"y1\", \"x2\", \"y2\"]] = df_tracked[[\"x1\", \"y1\", \"x2\", \"y2\"]].apply(\n",
    "            lambda x: scale_bbox_as_xyxy(x[0:4], detections.orig_shape), axis=1, result_type=\"expand\"\n",
    "        )\n",
    "\n",
    "        for i, row in df_tracked.iterrows():\n",
    "            x1, y1, x2, y2 = int(row[\"x1\"]), int(row[\"y1\"]), int(row[\"x2\"]), int(row[\"y2\"])\n",
    "            confidence = row[\"confidence\"]\n",
    "            class_id = row[\"class\"]\n",
    "            track_id = row[\"track_id\"]\n",
    "\n",
    "            label = f\"ID: {track_id} Conf: {confidence:.2f}\"\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
